<application>
  <component name="AppStorage">
    <histories>
      <item value="relinquishes" />
      <item value="Sets head of queue, and checks if successor may be waiting in shared mode, if so propagating if either propagate &gt; 0 or PROPAGATE status was set." />
      <item value=" Otherwise the thread is queued, possibly repeatedly blocking and unblocking, invoking tryAcquireShared until success" />
      <item value="Acquires in shared mode, ignoring interrupts. Implemented by first invoking at least once tryAcquireShared, returning on success." />
      <item value="As a heuristic to avoid indefinite writer starvation" />
      <item value="barge" />
      <item value="Attempts to set the state to reflect a release in shared mode." />
      <item value="true if this release of shared mode may permit a waiting acquire (shared or exclusive) to succeed; and false otherwise" />
      <item value=" Decrement count; signal when transition to zero" />
      <item value="lies dormant " />
      <item value="dormant" />
      <item value="A useful property of a CountDownLatch is that it doesn't require that threads calling countDown wait for the count to reach zero before proceeding, it simply prevents any thread from proceeding past an await until all threads could pass." />
      <item value="versatile" />
      <item value=" This is a one-shot phenomenon -- the count cannot be reset. If you need a version that resets the count, consider using a CyclicBarrier" />
      <item value="A CountDownLatch is initialized with a given count. The await methods block until the current count reaches zero due to invocations of the countDown method" />
      <item value="A template trait for collections which can be traversed either once only or one or more times.&#10;" />
      <item value="eligible" />
      <item value="precisely" />
      <item value="Accessed via a benign data race; relies on the memory model's out-of-thin-air guarantees for references.&#10;This allows tracking of read holds for uncontended read locks to be very cheap." />
      <item value="relinquishing" />
      <item value="Cannot cause garbage retention unless the thread terminated without relinquishing its read locks, since tryReleaseShared sets it to null." />
      <item value="&#10;More precisely, firstReader is the unique thread that last changed the shared count from 0 to 1, and has not released the read lock since then; null if there is no such thread." />
      <item value="More precisely" />
      <item value="Acquires only if reentrant or queue is empty." />
      <item value="A synchronizer that may be exclusively owned by a thread. This class provides a basis for creating locks and related synchronizers that may entail a notion of ownership. The AbstractOwnableSynchronizer class itself does not manage or use this information. However, subclasses and tools may use appropriately maintained values to help control and monitor access and provide diagnostics." />
      <item value="true if synchronization is held exclusively;" />
      <item value="Returns true if synchronization is held exclusively with respect to the current (calling) thread. This method is invoked upon each call to a AbstractQueuedSynchronizer.ConditionObject method." />
      <item value="If the lock is not available then the current thread becomes disabled for thread scheduling purposes and lies dormant until one of two things happens" />
      <item value="Acquires the lock if it is not held by another thread and returns immediately, setting the lock hold count to one." />
      <item value="In addition to" />
      <item value="&#10;In addition to implementing the Lock interface, this class defines a number of public and protected methods for inspecting the state of the lock. Some of these methods are only useful for instrumentation and monitoring." />
      <item value="&#10;The constructor for this class accepts an optional fairness parameter. When set true, under contention, locks favor granting access to the longest-waiting thread." />
      <item value="A reentrant mutual exclusion Lock with the same basic behavior and semantics as the implicit monitor lock accessed using synchronized methods and statements, but with extended capabilities." />
      <item value="This class does not impose a reader or writer preference ordering for lock access. However, it does support an optional fairness policy." />
      <item value="It should be called from the Synchronization Context. Currently will log a warning if violated. It will become an exception eventually. See 5015  for the background." />
      <item value="If there isn't an active transport yet, and an RPC is assigned to the Subchannel, it will create a new transport. It won't actively create transports otherwise. requestConnection() can be used to ask Subchannel to create a transport if there isn't any.&#10;" />
      <item value="It maintains at most one physical connection (aka transport) for sending new RPCs, while also keeps track of previous transports that has been shut down but not terminated yet." />
      <item value="A logical connection to a server, or a group of equivalent servers represented by an EquivalentAddressGrou" />
      <item value="This transport owns every stream that it has created until a real transport has been picked for that stream, at which point the ownership of the stream is transferred to the real transport, thus the delayed transport stops owning the stream" />
      <item value="When reprocess is called, this class applies the provided io.grpc.LoadBalancer.SubchannelPicker to pick a transport for each pending stream" />
      <item value="&#10;a Runnable that is executed after-the-fact by the original caller, typically after locks are released" />
      <item value="Implementations must not call listener from within start; implementations are expected to notify listener on a separate thread or when the returned Runnable is run. This method and the returned Runnable should not throw any exceptions." />
      <item value="An object that executes submitted Runnable tasks. This interface provides a way of decoupling task submission from the mechanics of how each task will be run, including details of thread use, scheduling, etc. An Executor is normally used instead of explicitly creating threads. For example, rather than invoking new Thread(new RunnableTask()).start() for each of a set of tasks" />
      <item value="Internal Instrumented" />
      <item value="drain" />
      <item value="When a buffer is added to a composite, its life cycle is controlled by the composite. Once the composite has read past the end of a given buffer, that buffer is automatically closed and removed from the composite." />
      <item value="A ReadableBuffer that is composed of 0 or more ReadableBuffers." />
      <item value="Deframer for GRPC frames." />
      <item value="frames" />
      <item value="Deframer" />
    </histories>
    <option name="languageScores">
      <map>
        <entry key="CHINESE" value="226" />
        <entry key="ENGLISH" value="227" />
      </map>
    </option>
  </component>
  <component name="Cache">
    <option name="lastTrimTime" value="1657497824818" />
  </component>
  <component name="Settings">
    <option name="keepFormat" value="true" />
  </component>
</application>